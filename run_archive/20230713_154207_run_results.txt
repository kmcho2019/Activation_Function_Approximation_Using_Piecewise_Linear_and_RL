C:\Users\kmcho\Documents\ISOCC_2023\Activation_function_approximations\venv\Scripts\python.exe C:\Users\kmcho\Documents\ISOCC_2023\Activation_function_approximations\RL_PPO_SB3.py 
silu Run:
Running with OneCycleLR_Schedule_Linear_MinLR and config {'initial_value': 0.0005, 'warmup_proportion': 0.1, 'multiplier': 20}
Run #1
C:\Users\kmcho\Documents\ISOCC_2023\Activation_function_approximations\venv\Lib\site-packages\stable_baselines3\common\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
 100% ------------------------ 200,704/200,000  [ 0:45:23 < 0:00:00 , 66 it/s ]
Final Model Evaluation Results:
Mean Reward: 74.565961, Std Reward: 0.0
Final Chosen Points:  [-4.505894148349762, -1.289775598049164, -0.7008425116539004, -0.18967798948287992, 0.31664091348648044, 0.8529154419898984, 1.5134854435920713, 4.206376183032988]
Final Reward:  73.47270922157003
Mean Error:  0.00463080319163915
Max Error:  0.015730418947415004
Best Model Evaluation Results:
Mean Reward: 75.82170088815474, Std Reward: 0.0
Final Chosen Points:  [-4.503076696395874, -1.2572349190711978, -0.5791022896766665, -0.017668879032135293, 0.5579804778099057, 1.2726364493370053, 2.358189475536346, 4.178266990184783]
Final Reward:  74.73989406854513
Mean Error:  0.004950091179191697
Max Error:  0.01536214634714126
Running with OneCycleLR_Schedule_Linear_MinLR and config {'initial_value': 0.001, 'warmup_proportion': 0.1, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:47:24 < 0:00:00 , 63 it/s ]
Final Model Evaluation Results:
Mean Reward: 70.741409, Std Reward: 0.0
Final Chosen Points:  [-5.249680542945862, -2.616938400268555, -1.421733331680298, -0.6497252941131594, -0.008025169372558788, 0.5888122081756589, 1.3687011718749997, 3.934139776229858]
Final Reward:  69.66411432556698
Mean Error:  0.005786050248568234
Max Error:  0.016371728547021736
Best Model Evaluation Results:
Mean Reward: 70.63771304348484, Std Reward: 0.0
Final Chosen Points:  [-5.252131605148316, -2.6221870660781863, -1.4281364202499391, -0.6551937818527224, -0.015975832939148144, 0.5811364412307737, 1.360557150840759, 3.920792031288147]
Final Reward:  69.56027743294155
Mean Error:  0.005809787300847044
Max Error:  0.016392579260509965
Running with OneCycleLR_Schedule_Linear_MinLR and config {'initial_value': 0.005, 'warmup_proportion': 0.1, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:49:05 < 0:00:00 , 77 it/s ]
Final Model Evaluation Results:
Mean Reward: 49.616959, Std Reward: 0.0
Final Chosen Points:  [-6.0285474300384525, -3.9305212974548343, -1.9776708602905275, -0.8783780097961428, -0.14441704750061055, 0.6171382427215574, 1.5267860412597654, 3.414199876785278]
Final Reward:  48.54971879463206
Mean Error:  0.006942723040499459
Max Error:  0.02388612130246931
Best Model Evaluation Results:
Mean Reward: 60.80312728980789, Std Reward: 0.0
Final Chosen Points:  [-5.816454315185547, -3.407155799865723, -1.6020540714263918, -0.7524450778961184, -0.03895020484924336, 0.6311241149902341, 1.5096303939819333, 3.7014705419540403]
Final Reward:  59.73019873488044
Mean Error:  0.005590743239566062
Max Error:  0.0194047516752619
Running with OneCycleLR_Schedule_Linear_MinLR and config {'initial_value': 0.0005, 'warmup_proportion': 0.2, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:43:26 < 0:00:00 , 61 it/s ]
Final Model Evaluation Results:
Mean Reward: 74.96377900000002, Std Reward: 1.4210854715202004e-14
Final Chosen Points:  [-4.557078266143799, -1.2667655825614932, -0.7134152770042422, -0.17399815320968656, 0.28778892755508395, 0.843719160556793, 1.4700830101966855, 4.159397828578948]
Final Reward:  73.86954075654383
Mean Error:  0.0046950240255924855
Max Error:  0.015622968255022407
Best Model Evaluation Results:
Mean Reward: 74.59750587551389, Std Reward: 0.0
Final Chosen Points:  [-4.552712345123291, -1.265845584869385, -0.7010859966278079, -0.16043863296508817, 0.2991187572479245, 0.8620444297790525, 1.5001539707183835, 4.16659801006317]
Final Reward:  73.50383439759717
Mean Error:  0.004696729440322054
Max Error:  0.01570673318493032
Running with OneCycleLR_Schedule_Linear_MinLR and config {'initial_value': 0.001, 'warmup_proportion': 0.2, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:50:20 < 0:00:00 , 61 it/s ]
Final Model Evaluation Results:
Mean Reward: 72.81350699999999, Std Reward: 1.4210854715202004e-14
Final Chosen Points:  [-4.68176885843277, -1.7623929858207705, -1.139402759075165, -0.4610357642173769, 0.0981474518775938, 0.6804453492164609, 1.392597687244415, 4.071263182163238]
Final Reward:  71.72766094830862
Mean Error:  0.0052665766791490385
Max Error:  0.01598538444753831
Best Model Evaluation Results:
Mean Reward: 72.80295237328392, Std Reward: 0.0
Final Chosen Points:  [-4.700212740898133, -1.7831988811492923, -1.1592521190643312, -0.4813960552215578, 0.08799886703491192, 0.665428018569946, 1.3806704998016355, 4.047788786888122]
Final Reward:  71.7173627636146
Mean Error:  0.005328602911332945
Max Error:  0.015972380306654002
Running with OneCycleLR_Schedule_Linear_MinLR and config {'initial_value': 0.005, 'warmup_proportion': 0.2, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:34:16 < 0:00:00 , 66 it/s ]
Final Model Evaluation Results:
Mean Reward: 4.515036, Std Reward: 0.0
Final Chosen Points:  [0.1, 0.44244379997253414, 0.5424437999725341, 0.8855237007141112, 1.6315410137176514, 2.1566978454589845, 3.068041276931763, 3.4709830760955813]
Final Reward:  4.4519508333734805
Mean Error:  0.02718185998999311
Max Error:  0.2738553222438016
Best Model Evaluation Results:
Mean Reward: 49.86147788329981, Std Reward: 0.0
Final Chosen Points:  [-5.509436750411988, -2.761014270782471, -1.403795909881592, -0.5208004474639895, 0.1614356040954588, 0.9415882587432859, 1.9939965724945066, 3.5191550731658934]
Final Reward:  48.792985991359004
Mean Error:  0.007669971778288108
Max Error:  0.023575943283564715
Running with OneCycleLR_Schedule_Cosine and config {'initial_value': 0.0005, 'warmup_proportion': 0.1, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:56:01 < 0:00:00 , 70 it/s ]
Final Model Evaluation Results:
Mean Reward: 74.97647000000002, Std Reward: 1.4210854715202004e-14
Final Chosen Points:  [-4.455333733558655, -1.2658485651016238, -0.6609109163284305, -0.12161872386932401, 0.3563185930252072, 0.9152402639389035, 1.540986609458923, 4.262085247039794]
Final Reward:  73.88452345313584
Mean Error:  0.004613621305245401
Max Error:  0.015639887457871815
Best Model Evaluation Results:
Mean Reward: 75.44528400758281, Std Reward: 0.0
Final Chosen Points:  [-4.518383646011353, -1.2853188991546634, -0.7043456554412845, -0.17453083992004423, 0.2937102317810056, 0.8489469051361082, 1.4552719116210935, 4.17277317047119]
Final Reward:  74.35131128698787
Mean Error:  0.004631643020326396
Max Error:  0.015529166642923364
Running with OneCycleLR_Schedule_Cosine and config {'initial_value': 0.001, 'warmup_proportion': 0.1, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:44:18 < 0:00:00 , 69 it/s ]
Final Model Evaluation Results:
Mean Reward: 74.05401800000001, Std Reward: 1.4210854715202004e-14
Final Chosen Points:  [-4.578559482097626, -1.2419401288032534, -1.1419401288032534, -0.45049086809158345, 0.07743972539901714, 0.6895449519157407, 1.3671597361564634, 4.011188375949859]
Final Reward:  72.9592761014246
Mean Error:  0.005206255470621517
Max Error:  0.01570628156055731
Best Model Evaluation Results:
Mean Reward: 73.90794732794166, Std Reward: 0.0
Final Chosen Points:  [-4.588232421875, -1.2565627574920657, -1.1565627574920656, -0.46119914054870625, 0.07004570960998516, 0.6805277824401853, 1.3594820022583005, 3.9970552206039427]
Final Reward:  72.81348494872974
Mean Error:  0.0052437379538111525
Max Error:  0.015731215262450693
Running with OneCycleLR_Schedule_Cosine and config {'initial_value': 0.005, 'warmup_proportion': 0.1, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:40:20 < 0:00:00 , 57 it/s ]
Final Model Evaluation Results:
Mean Reward: 40.475755, Std Reward: 0.0
Final Chosen Points:  [-5.825154328346253, -1.1486411571502688, -0.6150743484497073, 0.03463020324707003, 0.6351728439331051, 1.5103815555572506, 3.5001637458801267, 5.218893098831176]
Final Reward:  39.39634974705055
Mean Error:  0.008349917247292052
Max Error:  0.029516348562479797
Best Model Evaluation Results:
Mean Reward: 45.603126689675264, Std Reward: 0.0
Final Chosen Points:  [-5.764999532699585, -3.523500728607178, -1.7852129459381105, -0.7517724990844729, 0.0018658638000486338, 0.7217255592346189, 1.6674551486968991, 3.327969121932983]
Final Reward:  44.53547360943746
Mean Error:  0.0071493962793149355
Max Error:  0.02615516427834219
Running with OneCycleLR_Schedule_Cosine and config {'initial_value': 0.0005, 'warmup_proportion': 0.2, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:42:46 < 0:00:00 , 70 it/s ]
Final Model Evaluation Results:
Mean Reward: 75.239543, Std Reward: 0.0
Final Chosen Points:  [-4.514249885082245, -1.3140945911407473, -0.7259418487548831, -0.18260989189147978, 0.3043205738067624, 0.8597596645355222, 1.4868416309356687, 4.22775011062622]
Final Reward:  74.14682173792151
Mean Error:  0.004625688396134596
Max Error:  0.015577021333892382
Best Model Evaluation Results:
Mean Reward: 75.15565253410023, Std Reward: 0.0
Final Chosen Points:  [-4.516056799888611, -1.3118727684020999, -0.7283863544464114, -0.19828972816467313, 0.3023355007171628, 0.8534258365631101, 1.4817161083221433, 4.20426206588745]
Final Reward:  74.06265104055467
Mean Error:  0.004624371170406319
Max Error:  0.01559650991858863
Running with OneCycleLR_Schedule_Cosine and config {'initial_value': 0.001, 'warmup_proportion': 0.2, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:46:24 < 0:00:00 , 72 it/s ]
Final Model Evaluation Results:
Mean Reward: 71.40109600000001, Std Reward: 1.4210854715202004e-14
Final Chosen Points:  [-5.690380477905274, -3.423574018478394, -1.4041871547698976, -0.6231204032897951, -0.018910408020019726, 0.6148596763610837, 1.3559717655181882, 3.8846210718154905]
Final Reward:  70.32239666435139
Mean Error:  0.0048215287984632845
Max Error:  0.016444893662585613
Best Model Evaluation Results:
Mean Reward: 71.09220901381923, Std Reward: 0.0
Final Chosen Points:  [-5.690069699287415, -3.419218945503235, -1.395832133293152, -0.6100790262222292, -0.0063894987106325185, 0.6267688035964963, 1.3732653379440305, 3.8913683176040648]
Final Reward:  70.01372220836895
Mean Error:  0.004806266825173967
Max Error:  0.016527076273576302
Running with OneCycleLR_Schedule_Cosine and config {'initial_value': 0.005, 'warmup_proportion': 0.2, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:39:14 < 0:00:00 , 69 it/s ]
Final Model Evaluation Results:
Mean Reward: 26.698867999999997, Std Reward: 3.552713678800501e-15
Final Chosen Points:  [-6.298967266082764, -1.1740729093551638, -0.2751413106918338, 0.7763586282730099, 2.000778794288635, 3.7721483469009396, 5.708385062217712, 6.158174204826354]
Final Reward:  25.645494265656282
Mean Error:  0.012111565002995152
Max Error:  0.045588614257061386
Best Model Evaluation Results:
Mean Reward: 50.77434081811225, Std Reward: 0.0
Final Chosen Points:  [-5.532150411605835, -3.0823193073272708, -1.4179589271545412, -0.5971916675567629, 0.06644296646118145, 0.7439564228057859, 1.6865298271179197, 3.484263706207275]
Final Reward:  49.700784350728014
Mean Error:  0.006921025063168715
Max Error:  0.02329525224890272
Running with OneCycleLR_Schedule_Exponential and config {'initial_value': 0.0005, 'warmup_proportion': 0.1, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:43:56 < 0:00:00 , 73 it/s ]
Final Model Evaluation Results:
Mean Reward: 56.206218, Std Reward: 0.0
Final Chosen Points:  [-4.229613596200943, -1.5731749117374423, -0.9305304110050204, -0.30570626854896576, 0.30990728735923734, 1.030227845907211, 2.1788804948329923, 4.13391174674034]
Final Reward:  55.12492486248356
Mean Error:  0.005211700403622922
Max Error:  0.021247842768498004
Best Model Evaluation Results:
Mean Reward: 61.526688641286455, Std Reward: 0.0
Final Chosen Points:  [-4.155954027175904, -1.607298302650452, -0.9416087388992312, -0.2705409288406375, 0.3558667898178097, 1.071559405326843, 2.194656443595886, 4.054936337471008]
Final Reward:  60.447422180720004
Mean Error:  0.005273418897984853
Max Error:  0.01923577359735129
Running with OneCycleLR_Schedule_Exponential and config {'initial_value': 0.001, 'warmup_proportion': 0.1, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:41:08 < 0:00:00 , 78 it/s ]
Final Model Evaluation Results:
Mean Reward: 73.204845, Std Reward: 0.0
Final Chosen Points:  [-4.625401759147644, -1.2981630444526675, -0.7261655449867251, -0.20636907815933256, 0.2870885729789731, 0.8414383292198179, 1.5033787608146665, 4.1155478835105885]
Final Reward:  72.1112998788228
Mean Error:  0.00482621756178842
Max Error:  0.016002760787625178
Best Model Evaluation Results:
Mean Reward: 73.24231349665206, Std Reward: 0.0
Final Chosen Points:  [-4.616094315052033, -1.2817665815353396, -0.7005127191543582, -0.1720785856246951, 0.31650841236114474, 0.8702549695968625, 1.5349448442459104, 4.111296582221984]
Final Reward:  72.14946778297522
Mean Error:  0.00482021893352301
Max Error:  0.015995090391181854
Running with OneCycleLR_Schedule_Exponential and config {'initial_value': 0.005, 'warmup_proportion': 0.1, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:44:00 < 0:00:00 , 54 it/s ]
Final Model Evaluation Results:
Mean Reward: 77.606035, Std Reward: 0.0
Final Chosen Points:  [-4.41655912399292, -1.280210900306702, -0.7742398500442508, -0.18723175525665312, 0.2774428129196164, 0.8482079267501829, 1.3748195886611936, 4.232069063186644]
Final Reward:  76.5118594182176
Mean Error:  0.004619900348193746
Max Error:  0.015057361497172295
Best Model Evaluation Results:
Mean Reward: 77.58381876710337, Std Reward: 0.0
Final Chosen Points:  [-4.436493003368378, -1.3092300176620486, -0.7830696821212771, -0.19651172161102323, 0.2775598764419553, 0.8425562143325803, 1.3765395402908323, 4.233264613151549]
Final Reward:  76.49018119760805
Mean Error:  0.004589390882000949
Max Error:  0.015069619057832995
Running with OneCycleLR_Schedule_Exponential and config {'initial_value': 0.0005, 'warmup_proportion': 0.2, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:40:56 < 0:00:00 , 75 it/s ]
Final Model Evaluation Results:
Mean Reward: 61.83147499999999, Std Reward: 7.105427357601002e-15
Final Chosen Points:  [-4.711436831951142, -1.4555003523826602, -0.8276733279228213, -0.25863126516342194, 0.33262854814529386, 0.995560801029205, 1.9655823826789853, 4.307940590381621]
Final Reward:  60.746656586439386
Mean Error:  0.005565704145329094
Max Error:  0.019060838133281965
Best Model Evaluation Results:
Mean Reward: 66.68594825547189, Std Reward: 0.0
Final Chosen Points:  [-4.679332637786866, -1.4382907629013064, -0.7996388196945193, -0.22273204326629667, 0.3626407384872433, 0.9990579843521115, 1.9433124780654905, 4.203941750526427]
Final Reward:  65.60105151454167
Mean Error:  0.005436528297120277
Max Error:  0.01757044054522916
Running with OneCycleLR_Schedule_Exponential and config {'initial_value': 0.001, 'warmup_proportion': 0.2, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:40:12 < 0:00:00 , 73 it/s ]
Final Model Evaluation Results:
Mean Reward: 76.068631, Std Reward: 0.0
Final Chosen Points:  [-4.321286016702652, -1.3658344328403476, -0.7447832643985751, -0.22206092476844816, 0.27689895033836337, 0.816639846563339, 1.4330070436000821, 4.21143438220024]
Final Reward:  74.97525086579829
Mean Error:  0.004480464302352265
Max Error:  0.015427052214151082
Best Model Evaluation Results:
Mean Reward: 75.78873642138205, Std Reward: 0.0
Final Chosen Points:  [-4.333580577373505, -1.3848588347435, -0.7444812178611758, -0.22650722265243559, 0.2867313027381894, 0.835054552555084, 1.4511172890663144, 4.211321461200713]
Final Reward:  74.69619654577153
Mean Error:  0.004495075860321166
Max Error:  0.015485684163788704
Running with OneCycleLR_Schedule_Exponential and config {'initial_value': 0.005, 'warmup_proportion': 0.2, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:39:56 < 0:00:00 , 76 it/s ]
Final Model Evaluation Results:
Mean Reward: 73.58639400000001, Std Reward: 1.4210854715202004e-14
Final Chosen Points:  [-4.6563152313232425, -1.200252163410187, -0.5383293747901919, 0.06583436727523775, 0.6439706683158871, 1.3901570200920101, 2.358897817134857, 4.147513616085051]
Final Reward:  72.50675874980998
Mean Error:  0.005144304884344872
Max Error:  0.01582869592640722
Best Model Evaluation Results:
Mean Reward: 74.96508733509108, Std Reward: 0.0
Final Chosen Points:  [-4.646050357818604, -1.1471881151199343, -0.5023244142532352, 0.09035327434539767, 0.6723090410232541, 1.3861202955245968, 2.3266175508499143, 4.1176528215408315]
Final Reward:  73.88495343490888
Mean Error:  0.0051686329830262735
Max Error:  0.015501036080524278
sigmoid Run:
Running with OneCycleLR_Schedule_Linear_MinLR and config {'initial_value': 0.0005, 'warmup_proportion': 0.1, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:39:48 < 0:00:00 , 70 it/s ]
Final Model Evaluation Results:
Mean Reward: 193.722685, Std Reward: 0.0
Final Chosen Points:  [-4.003743568062783, -2.6059406429529193, -1.6658250957727434, -0.8888031154870989, 0.8804039806127546, 1.6864472240209578, 2.621025976538658, 4.06317785680294]
Final Reward:  192.6926002197905
Mean Error:  0.001815787020177373
Max Error:  0.005908069345076861
Best Model Evaluation Results:
Mean Reward: 193.35031451284885, Std Reward: 0.0
Final Chosen Points:  [-4.009288081526757, -2.5949715703725817, -1.661859092116356, -0.8728093713521959, 0.8647753149271009, 1.6746170431375502, 2.6385422617197034, 4.090476694703102]
Final Reward:  192.32035329688847
Mean Error:  0.0018025532538520667
Max Error:  0.005923933773274739
Running with OneCycleLR_Schedule_Linear_MinLR and config {'initial_value': 0.001, 'warmup_proportion': 0.1, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:40:05 < 0:00:00 , 81 it/s ]
Final Model Evaluation Results:
Mean Reward: 124.29706600000002, Std Reward: 1.4210854715202004e-14
Final Chosen Points:  [-4.3912406206130985, -3.184439826011658, -2.2676614046096804, -1.2834002733230592, -0.25601041316986095, 1.007822012901306, 2.0968044519424436, 3.6350478410720823]
Final Reward:  123.27072618043408
Mean Error:  0.002321802672715564
Max Error:  0.009434831933631593
Best Model Evaluation Results:
Mean Reward: 179.60337945749052, Std Reward: 0.0
Final Chosen Points:  [-4.479039633274079, -2.7962547421455386, -1.7978406071662905, -0.8811935544013979, 0.810248553752899, 1.6105265974998473, 2.548663747310638, 3.9504310965538023]
Final Reward:  178.5742161275558
Mean Error:  0.0017688464706550773
Max Error:  0.0064326791118417895
Running with OneCycleLR_Schedule_Linear_MinLR and config {'initial_value': 0.005, 'warmup_proportion': 0.1, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:45:58 < 0:00:00 , 69 it/s ]
Final Model Evaluation Results:
Mean Reward: 66.655836, Std Reward: 0.0
Final Chosen Points:  [-6.545549297332764, -6.009129810333253, -4.595156383514405, -4.495156383514406, -2.4459650516510023, -1.4778129100799573, 1.4063857316970814, 3.0668625116348256]
Final Reward:  65.63654308191282
Mean Error:  0.004390654886171468
Max Error:  0.017821605542303498
Best Model Evaluation Results:
Mean Reward: 128.482277190662, Std Reward: 0.0
Final Chosen Points:  [-4.0567502617836, -2.467875111103058, -1.4805839180946352, -0.4273084759712221, 0.9687377810478208, 1.972717797756195, 3.1501757025718686, 5.319024074077605]
Final Reward:  127.45600826294782
Mean Error:  0.002158455596679369
Max Error:  0.009142691515739987
Running with OneCycleLR_Schedule_Linear_MinLR and config {'initial_value': 0.0005, 'warmup_proportion': 0.2, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:43:53 < 0:00:00 , 70 it/s ]
Final Model Evaluation Results:
Mean Reward: 198.88534299999998, Std Reward: 2.842170943040401e-14
Final Chosen Points:  [-4.044525513052941, -2.623648199439049, -1.6846365302801134, -0.8841224521398546, 0.9003474861383436, 1.6690908581018447, 2.621281591057777, 4.032114806771278]
Final Reward:  197.85526617810942
Mean Error:  0.0018141555855199583
Max Error:  0.005739210558288299
Best Model Evaluation Results:
Mean Reward: 199.28458975092508, Std Reward: 0.0
Final Chosen Points:  [-4.057382473349572, -2.630254063010216, -1.68857019841671, -0.8842435687780382, 0.8934412151575086, 1.6673141628503798, 2.6218464046716687, 4.0349963337183]
Final Reward:  198.2545678959143
Mean Error:  0.0018068398890152425
Max Error:  0.005728314992700656
Running with OneCycleLR_Schedule_Linear_MinLR and config {'initial_value': 0.001, 'warmup_proportion': 0.2, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:45:47 < 0:00:00 , 68 it/s ]
Final Model Evaluation Results:
Mean Reward: 150.171715, Std Reward: 0.0
Final Chosen Points:  [-5.327817463874817, -3.114960837364197, -1.9225338220596315, -0.9097711801528933, 0.6045724153518675, 1.3475501298904418, 2.382480692863464, 3.811779189109802]
Final Reward:  149.14394566375228
Mean Error:  0.0020750044765025216
Max Error:  0.007737413764483843
Best Model Evaluation Results:
Mean Reward: 150.94732325171935, Std Reward: 0.0
Final Chosen Points:  [-5.3281467199325565, -3.1192939758300784, -1.9200081348419191, -0.8985463142395022, 0.6174874305725095, 1.3637338638305663, 2.3946268081665036, 3.824085760116577]
Final Reward:  149.91957717924237
Mean Error:  0.0020578622195283067
Max Error:  0.007698338109715458
Running with OneCycleLR_Schedule_Linear_MinLR and config {'initial_value': 0.005, 'warmup_proportion': 0.2, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:39:59 < 0:00:00 , 68 it/s ]
Final Model Evaluation Results:
Mean Reward: 6.455496999999999, Std Reward: 8.881784197001252e-16
Final Chosen Points:  [0.1, 2.2668296813964846, 2.3668296813964846, 3.4901944637298588, 4.3007893562316895, 5.035755014419555, 6.3334960460662835, 6.433496046066283]
Final Reward:  6.443381145955212
Mean Error:  0.05058750965576876
Max Error:  0.18122564837027727
Best Model Evaluation Results:
Mean Reward: 104.89414504595334, Std Reward: 0.0
Final Chosen Points:  [-5.549872899055481, -3.581464457511902, -2.539988112449646, -1.6317264795303346, -0.4905747175216676, 0.9633135557174681, 2.057867360115051, 3.7727290868759153]
Final Reward:  103.86850240724748
Mean Error:  0.0023615212851529075
Max Error:  0.01131906680204664
Running with OneCycleLR_Schedule_Cosine and config {'initial_value': 0.0005, 'warmup_proportion': 0.1, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:45:40 < 0:00:00 , 69 it/s ]
Final Model Evaluation Results:
Mean Reward: 199.225676, Std Reward: 0.0
Final Chosen Points:  [-4.035620772838593, -2.6294698596000674, -1.698705565929413, -0.89996794462204, 0.8840995430946348, 1.6726509690284728, 2.624496233463287, 4.036230909824371]
Final Reward:  198.19564350682393
Mean Error:  0.0018121430517636214
Max Error:  0.005728863712157608
Best Model Evaluation Results:
Mean Reward: 198.9016157152364, Std Reward: 0.0
Final Chosen Points:  [-4.03420556485653, -2.6270294517278674, -1.6939029067754747, -0.8942721694707872, 0.872779384255409, 1.6770957618951796, 2.6207875877618787, 4.041127744317055]
Final Reward:  197.87162719907494
Mean Error:  0.0018087165298871764
Max Error:  0.005740047938908168
Running with OneCycleLR_Schedule_Cosine and config {'initial_value': 0.001, 'warmup_proportion': 0.1, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:45:50 < 0:00:00 , 69 it/s ]
Final Model Evaluation Results:
Mean Reward: 162.331258, Std Reward: 0.0
Final Chosen Points:  [-5.014676475524903, -3.0269365787506106, -1.9128636837005617, -0.9318536281585695, 0.7770912647247312, 1.4533389568328856, 2.4691836357116697, 3.8669004917144774]
Final Reward:  161.30264433864346
Mean Error:  0.0018974278749271441
Max Error:  0.00715005101602334
Best Model Evaluation Results:
Mean Reward: 161.92819147737464, Std Reward: 0.0
Final Chosen Points:  [-5.014213824272156, -3.019860672950745, -1.9064369916915895, -0.929376816749573, 0.7799764871597288, 1.4602651357650756, 2.476880383491516, 3.8668596029281614]
Final Reward:  160.89956808606001
Mean Error:  0.0018985254574064216
Max Error:  0.007169189987184993
Running with OneCycleLR_Schedule_Cosine and config {'initial_value': 0.005, 'warmup_proportion': 0.1, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:44:03 < 0:00:00 , 69 it/s ]
Final Model Evaluation Results:
Mean Reward: 176.379248, Std Reward: 0.0
Final Chosen Points:  [-4.2953412473201755, -2.6329895436763766, -1.7311773717403414, -0.7308618485927584, 0.6541558802127836, 1.6243317186832427, 2.4725328505039212, 4.041566568613052]
Final Reward:  175.35060543954154
Mean Error:  0.0019583073688824717
Max Error:  0.0065139984875690615
Best Model Evaluation Results:
Mean Reward: 173.99224893481005, Std Reward: 0.0
Final Chosen Points:  [-4.304835611581803, -2.644552904367447, -1.7512942373752596, -0.7588334143161776, 0.6383820474147794, 1.603713697195053, 2.4526465356349942, 4.015413421392441]
Final Reward:  172.96353320259803
Mean Error:  0.001966078335813208
Max Error:  0.0066104373176256725
Running with OneCycleLR_Schedule_Cosine and config {'initial_value': 0.0005, 'warmup_proportion': 0.2, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:41:04 < 0:00:00 , 73 it/s ]
Final Model Evaluation Results:
Mean Reward: 200.261951, Std Reward: 0.0
Final Chosen Points:  [-4.040130788087845, -2.634757596254349, -1.6898381531238558, -0.9072231113910677, 0.8918747603893278, 1.6881578624248503, 2.6366485774517057, 4.097411650419235]
Final Reward:  199.23198413165738
Mean Error:  0.0017924260464825426
Max Error:  0.005700986503354155
Best Model Evaluation Results:
Mean Reward: 202.5432004283648, Std Reward: 0.0
Final Chosen Points:  [-4.05073411166668, -2.646918031573296, -1.6969116896390917, -0.9084556311368944, 0.8875320702791212, 1.6909884721040724, 2.6288721829652784, 4.084932926297188]
Final Reward:  201.51327363942437
Mean Error:  0.0017912460176922461
Max Error:  0.0056302538193861995
Running with OneCycleLR_Schedule_Cosine and config {'initial_value': 0.001, 'warmup_proportion': 0.2, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:40:54 < 0:00:00 , 72 it/s ]
Final Model Evaluation Results:
Mean Reward: 167.895473, Std Reward: 0.0
Final Chosen Points:  [-3.829837495088577, -2.5757106125354765, -1.6515607655048368, -0.7913509666919706, 0.8120200335979464, 1.7435951888561252, 2.755489748716355, 4.4629666984081275]
Final Reward:  166.86641163961397
Mean Error:  0.0018560259231998237
Max Error:  0.006902015754997021
Best Model Evaluation Results:
Mean Reward: 186.8862379527418, Std Reward: 0.0
Final Chosen Points:  [-4.015883871912957, -2.5331302613019946, -1.6322717636823656, -0.7621132344007494, 0.8723406344652174, 1.7231321841478346, 2.6771358519792554, 4.1611149340867986]
Final Reward:  185.8566998856748
Mean Error:  0.001802815381078595
Max Error:  0.006149907880155944
Running with OneCycleLR_Schedule_Cosine and config {'initial_value': 0.005, 'warmup_proportion': 0.2, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:38:57 < 0:00:00 , 75 it/s ]
Final Model Evaluation Results:
Mean Reward: 2.237931, Std Reward: 0.0
Final Chosen Points:  [-7.9, -7.800000000000001, -7.700000000000001, -7.600000000000001, -7.500000000000002, -2.1215378284454363, 2.059869182109831, 3.8163711905479416]
Final Reward:  26.227107102452784
Mean Error:  0.010016038933245118
Max Error:  0.04503160320112474
Best Model Evaluation Results:
Mean Reward: 101.68318700970849, Std Reward: 0.0
Final Chosen Points:  [-5.911118650436402, -3.685205388069153, -2.3133722066879274, -1.1828224420547486, 0.219213843345642, 1.2091493368148805, 2.2285004377365114, 3.4645952463150027]
Final Reward:  100.65839438974315
Mean Error:  0.0026330583634430953
Max Error:  0.011634974420185601
Running with OneCycleLR_Schedule_Exponential and config {'initial_value': 0.0005, 'warmup_proportion': 0.1, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:40:35 < 0:00:00 , 75 it/s ]
Final Model Evaluation Results:
Mean Reward: 154.380729, Std Reward: 0.0
Final Chosen Points:  [-3.7857717290520667, -2.4377005353569983, -1.5052751794457433, -0.5346928372979162, 0.7135131582617762, 1.6396263822913173, 2.681887601315976, 4.243738006055356]
Final Reward:  153.35223748157912
Mean Error:  0.0020512062579501177
Max Error:  0.007513367407860537
Best Model Evaluation Results:
Mean Reward: 153.45607645390555, Std Reward: 0.0
Final Chosen Points:  [-3.811505952477455, -2.520968261361122, -1.5609013706445691, -0.6089960247278211, 0.6573781818151476, 1.5933757632970813, 2.6762477725744254, 4.313874039053918]
Final Reward:  152.4277113288104
Mean Error:  0.001999061057231764
Max Error:  0.00757584333305894
Running with OneCycleLR_Schedule_Exponential and config {'initial_value': 0.001, 'warmup_proportion': 0.1, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:43:12 < 0:00:00 , 70 it/s ]
Final Model Evaluation Results:
Mean Reward: 192.97116699999998, Std Reward: 2.842170943040401e-14
Final Chosen Points:  [-4.059478813409806, -2.6412572443485263, -1.7059620440006258, -0.8991935312747957, 0.8649824559688566, 1.6387781560420989, 2.5854974210262296, 4.009459155797958]
Final Reward:  191.94109449122573
Mean Error:  0.00181530011108317
Max Error:  0.005933589644623094
Best Model Evaluation Results:
Mean Reward: 198.5945715153357, Std Reward: 0.0
Final Chosen Points:  [-4.038764187693596, -2.6178019970655444, -1.6847085922956468, -0.8801652401685717, 0.8747288733720777, 1.6695049315690993, 2.631724265217781, 4.056681397557258]
Final Reward:  197.5646119370884
Mean Error:  0.0018021736098251973
Max Error:  0.005751500635157301
Running with OneCycleLR_Schedule_Exponential and config {'initial_value': 0.005, 'warmup_proportion': 0.1, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:43:27 < 0:00:00 , 69 it/s ]
Final Model Evaluation Results:
Mean Reward: 148.319178, Std Reward: 0.0
Final Chosen Points:  [-5.428324842453003, -3.1958150148391726, -1.9468067407608034, -0.9371487855911257, 0.5367110967636106, 1.2793779134750365, 2.3336930990219114, 3.773146319389343]
Final Reward:  147.29177048199173
Mean Error:  0.0021420936412867835
Max Error:  0.007826033550121847
Best Model Evaluation Results:
Mean Reward: 149.0143553420785, Std Reward: 0.0
Final Chosen Points:  [-5.422682189941407, -3.1831934928894046, -1.9408130168914797, -0.9300590515136721, 0.5494158267974851, 1.3042717933654784, 2.3505444049835202, 3.7716477394104]
Final Reward:  147.9868917961818
Mean Error:  0.002134570927150999
Max Error:  0.007788051328937506
Running with OneCycleLR_Schedule_Exponential and config {'initial_value': 0.0005, 'warmup_proportion': 0.2, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:40:32 < 0:00:00 , 68 it/s ]
Final Model Evaluation Results:
Mean Reward: 170.636072, Std Reward: 0.0
Final Chosen Points:  [-3.8812280386686324, -2.511254522204399, -1.5721875399351117, -0.7045955866575239, 0.6794961243867876, 1.5299186021089557, 2.4787409573793417, 3.9578994542360313]
Final Reward:  169.60636573594954
Mean Error:  0.001965734645917279
Max Error:  0.00675357273289183
Best Model Evaluation Results:
Mean Reward: 173.92604063951876, Std Reward: 0.0
Final Chosen Points:  [-3.929578238725662, -2.5140066921710966, -1.5508935272693631, -0.6694926083087919, 0.7096125781536105, 1.6070438086986545, 2.5909120261669165, 4.125232952833176]
Final Reward:  172.89691049747213
Mean Error:  0.0018941286997436941
Max Error:  0.006631209504099317
Running with OneCycleLR_Schedule_Exponential and config {'initial_value': 0.001, 'warmup_proportion': 0.2, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:43:40 < 0:00:00 , 75 it/s ]
Final Model Evaluation Results:
Mean Reward: 193.382947, Std Reward: 0.0
Final Chosen Points:  [-4.270288670063019, -2.7216416478157046, -1.7562847256660463, -0.9097336888313295, 0.9156340956687925, 1.6385591387748717, 2.622224700450897, 4.004606235027313]
Final Reward:  192.35321887167558
Mean Error:  0.00178123715976858
Max Error:  0.00592815227640113
Best Model Evaluation Results:
Mean Reward: 194.4685228744056, Std Reward: 0.0
Final Chosen Points:  [-4.299261206388474, -2.7426192939281466, -1.7726937949657442, -0.9136915862560274, 0.8961663544178007, 1.6313349068164824, 2.6134741127490995, 4.014616566896438]
Final Reward:  193.43892429991988
Mean Error:  0.0017640164936528224
Max Error:  0.005895983837509909
Running with OneCycleLR_Schedule_Exponential and config {'initial_value': 0.005, 'warmup_proportion': 0.2, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:43:30 < 0:00:00 , 73 it/s ]
Final Model Evaluation Results:
Mean Reward: 162.894524, Std Reward: 0.0
Final Chosen Points:  [-4.961341643333435, -3.0141932249069217, -1.9284520864486696, -0.9523334264755251, 0.9869226217269895, 1.890036082267761, 3.022551131248474, 4.90801327228546]
Final Reward:  161.8677892086623
Mean Error:  0.0016995167737719852
Max Error:  0.0071724725240357445
Best Model Evaluation Results:
Mean Reward: 166.36153629072942, Std Reward: 0.0
Final Chosen Points:  [-4.978913569450379, -3.0045158147811892, -1.913494658470154, -0.9243440389633181, 0.9537466764450071, 1.8901121377944945, 3.038911652565002, 4.947387385368346]
Final Reward:  165.33496576935812
Mean Error:  0.0017137011965013367
Max Error:  0.007006983923348191
gelu Run:
Running with OneCycleLR_Schedule_Linear_MinLR and config {'initial_value': 0.0005, 'warmup_proportion': 0.1, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:41:53 < 0:00:00 , 72 it/s ]
Final Model Evaluation Results:
Mean Reward: 99.14929900000001, Std Reward: 1.4210854715202004e-14
Final Chosen Points:  [-5.122293496131897, -2.4825969219207766, -0.7597169399261477, -0.3507946491241458, 0.024663925170898132, 0.3944252490997311, 0.8121125221252438, 2.541925001144409]
Final Reward:  98.01225091362898
Mean Error:  0.0021245375153601297
Max Error:  0.012097373354611918
Best Model Evaluation Results:
Mean Reward: 100.20485188545777, Std Reward: 0.0
Final Chosen Points:  [-5.1428532838821415, -2.5125349044799807, -0.757677507400513, -0.34803757667541535, 0.046692132949828796, 0.4277246952056881, 0.8593811511993404, 2.5626996040344237]
Final Reward:  99.07087970753673
Mean Error:  0.0021830636028769726
Max Error:  0.011946463336470092
Running with OneCycleLR_Schedule_Linear_MinLR and config {'initial_value': 0.001, 'warmup_proportion': 0.1, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:42:09 < 0:00:00 , 71 it/s ]
Final Model Evaluation Results:
Mean Reward: 104.8812, Std Reward: 0.0
Final Chosen Points:  [-5.2621584177017215, -2.510779905319214, -0.748860311508179, -0.3681560516357425, -0.012919664382934876, 0.3567393779754635, 0.7259258747100826, 2.580774116516113]
Final Reward:  103.73940490255713
Mean Error:  0.0021388316510613887
Max Error:  0.011389715362547737
Best Model Evaluation Results:
Mean Reward: 105.13529032403406, Std Reward: 1.4210854715202004e-14
Final Chosen Points:  [-5.266990447044373, -2.5213652133941653, -0.7651912689208987, -0.38882384300231965, -0.027624607086181946, 0.3393212318420407, 0.7121107101440426, 2.5796807289123533]
Final Reward:  103.9931720023144
Mean Error:  0.002143505160551123
Max Error:  0.011359143639364716
Running with OneCycleLR_Schedule_Linear_MinLR and config {'initial_value': 0.005, 'warmup_proportion': 0.1, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:42:47 < 0:00:00 , 70 it/s ]
Final Model Evaluation Results:
Mean Reward: 86.57941300000002, Std Reward: 1.4210854715202004e-14
Final Chosen Points:  [-5.615474843978882, -3.215777087211609, -2.4673829793930055, -0.7197942495346071, -0.23866736888885517, 0.17836925983428936, 0.6691239595413206, 2.542815613746643]
Final Reward:  85.461836093404
Mean Error:  0.002222829518054057
Max Error:  0.013945704328208686
Best Model Evaluation Results:
Mean Reward: 95.08257223163136, Std Reward: 0.0
Final Chosen Points:  [-5.612598443031311, -3.2053219556808474, -2.4705847024917604, -0.7119700670242312, -0.2234722375869753, 0.19703981876373272, 0.6915555715560912, 2.5269638776779173]
Final Reward:  93.96604200288468
Mean Error:  0.0022260217447248177
Max Error:  0.012621172567023678
Running with OneCycleLR_Schedule_Linear_MinLR and config {'initial_value': 0.0005, 'warmup_proportion': 0.2, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:41:02 < 0:00:00 , 73 it/s ]
Final Model Evaluation Results:
Mean Reward: 100.537508, Std Reward: 0.0
Final Chosen Points:  [-5.074748539924622, -2.4603069305419925, -0.7834717750549319, -0.379190540313721, -0.0051541328430178834, 0.36399564743041957, 0.7752530097961422, 2.54754524230957]
Final Reward:  99.39887662408472
Mean Error:  0.002108561343812891
Max Error:  0.011923454504291886
Best Model Evaluation Results:
Mean Reward: 101.02119705773148, Std Reward: 0.0
Final Chosen Points:  [-5.058676743507386, -2.4243779659271243, -0.8153247356414798, -0.3993621826171878, -0.005302190780639954, 0.3770023345947262, 0.7923373699188229, 2.5598652839660643]
Final Reward:  99.88514323255922
Mean Error:  0.002134542093561457
Max Error:  0.011855738081597789
Running with OneCycleLR_Schedule_Linear_MinLR and config {'initial_value': 0.001, 'warmup_proportion': 0.2, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:41:49 < 0:00:00 , 76 it/s ]
Final Model Evaluation Results:
Mean Reward: 104.97239099999999, Std Reward: 1.4210854715202004e-14
Final Chosen Points:  [-5.232530021667481, -2.5342951297760012, -0.7648217201232913, -0.3793695926666263, -0.02232575416564972, 0.34907875061035126, 0.710292291641235, 2.572568941116333]
Final Reward:  103.83067335742585
Mean Error:  0.0021505297867790113
Max Error:  0.011376199235509699
Best Model Evaluation Results:
Mean Reward: 104.9455925095177, Std Reward: 1.4210854715202004e-14
Final Chosen Points:  [-5.227806949615479, -2.5264955043792727, -0.7645749568939212, -0.37086710929870637, -0.00867390632629425, 0.36276421546936, 0.7192797183990475, 2.575376558303833]
Final Reward:  103.80488969770352
Mean Error:  0.002142996221704724
Max Error:  0.011381072901518241
Running with OneCycleLR_Schedule_Linear_MinLR and config {'initial_value': 0.005, 'warmup_proportion': 0.2, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:43:42 < 0:00:00 , 69 it/s ]
Final Model Evaluation Results:
Mean Reward: 95.695837, Std Reward: 0.0
Final Chosen Points:  [-6.075276279449463, -4.2985721111297615, -2.5462569713592536, -0.7224999427795417, -0.2404267787933356, 0.17568120956420835, 0.65940351486206, 2.6193051815032953]
Final Reward:  94.5798013731643
Mean Error:  0.0023554539295732677
Max Error:  0.012502489077580128
Best Model Evaluation Results:
Mean Reward: 95.46236557423143, Std Reward: 0.0
Final Chosen Points:  [-6.035236263275147, -4.229936408996583, -2.459673118591309, -0.7239814758300788, -0.2327971458435065, 0.18772253990173277, 0.6710943698883051, 2.62604169845581]
Final Reward:  94.34673475555806
Mean Error:  0.0022873923862418706
Max Error:  0.012552153082320938
Running with OneCycleLR_Schedule_Cosine and config {'initial_value': 0.0005, 'warmup_proportion': 0.1, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:41:50 < 0:00:00 , 74 it/s ]
Final Model Evaluation Results:
Mean Reward: 101.08794, Std Reward: 0.0
Final Chosen Points:  [-5.19735815525055, -2.4934068202972415, -0.7631139278411868, -0.3653336524963382, 0.030200004577636413, 0.4097624778747555, 0.8236004829406735, 2.565395402908325]
Final Reward:  99.95234532413043
Mean Error:  0.002153692041329241
Max Error:  0.011842536664214975
Best Model Evaluation Results:
Mean Reward: 100.81781143165617, Std Reward: 0.0
Final Chosen Points:  [-5.163046264648438, -2.4383414268493655, -0.7630114078521731, -0.3090733051300052, 0.10340476036071747, 0.5155228137969967, 0.9591011524200436, 2.5687768936157225]
Final Reward:  99.69037519498062
Mean Error:  0.002280102042439479
Max Error:  0.011843797796606825
Running with OneCycleLR_Schedule_Cosine and config {'initial_value': 0.001, 'warmup_proportion': 0.1, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:43:06 < 0:00:00 , 71 it/s ]
Final Model Evaluation Results:
Mean Reward: 105.44213199999999, Std Reward: 1.4210854715202004e-14
Final Chosen Points:  [-5.245920324325562, -2.527012395858765, -0.7362761020660403, -0.3382023334503177, 0.01174545288085907, 0.3864930629730221, 0.7199842453002926, 2.5811861038208006]
Final Reward:  104.30131678254648
Mean Error:  0.002158113499369654
Max Error:  0.011319979956975423
Best Model Evaluation Results:
Mean Reward: 105.37903478028781, Std Reward: 1.4210854715202004e-14
Final Chosen Points:  [-5.247840070724488, -2.5318091392517093, -0.7341722965240481, -0.3390296459198001, 0.009407997131347351, 0.38669571876525843, 0.7264570713043209, 2.5841489315032957]
Final Reward:  104.23824231873287
Mean Error:  0.002157119461417309
Max Error:  0.011327480281347224
Running with OneCycleLR_Schedule_Cosine and config {'initial_value': 0.005, 'warmup_proportion': 0.1, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:42:34 < 0:00:00 , 69 it/s ]
Final Model Evaluation Results:
Mean Reward: 8.775839000000001, Std Reward: 1.7763568394002505e-15
Final Chosen Points:  [0.1, 1.2149998664855959, 1.314999866485596, 2.6427163124084476, 3.7062306404113774, 4.782730674743652, 6.088592720031738, 6.424534368515014]
Final Reward:  8.739676298566001
Mean Error:  0.017619894803643944
Max Error:  0.1384959184828875
Best Model Evaluation Results:
Mean Reward: 56.949828032669885, Std Reward: 0.0
Final Chosen Points:  [-5.204906725883484, -2.218088555335999, -0.981895995140076, -0.4967984914779666, 0.0794459581375119, 0.6272654294967648, 1.7844434499740598, 2.624715971946716]
Final Reward:  55.8414396920843
Mean Error:  0.002808245471412929
Max Error:  0.021557748316363978
Running with OneCycleLR_Schedule_Cosine and config {'initial_value': 0.0005, 'warmup_proportion': 0.2, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:42:03 < 0:00:00 , 71 it/s ]
Final Model Evaluation Results:
Mean Reward: 102.70959, Std Reward: 0.0
Final Chosen Points:  [-5.433241152763367, -2.5060499191284182, -0.782084655761719, -0.3859899997711185, -0.018945455551147766, 0.34820756912231415, 0.7421719551086422, 2.5630186080932615]
Final Reward:  101.56947650351857
Mean Error:  0.002132763890325347
Max Error:  0.011648655956542076
Best Model Evaluation Results:
Mean Reward: 101.97401639728983, Std Reward: 1.4210854715202004e-14
Final Chosen Points:  [-5.412723565101624, -2.4620342731475833, -0.7598480701446536, -0.3368299961090091, 0.05300831794738739, 0.4433198928833004, 0.8508617401123043, 2.5794511318206785]
Final Reward:  100.84038957348919
Mean Error:  0.0022149327206062172
Max Error:  0.011717093584173277
Running with OneCycleLR_Schedule_Cosine and config {'initial_value': 0.001, 'warmup_proportion': 0.2, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:42:45 < 0:00:00 , 69 it/s ]
Final Model Evaluation Results:
Mean Reward: 90.85827900000001, Std Reward: 1.4210854715202004e-14
Final Chosen Points:  [-5.531187915802002, -3.1522315025329593, -2.0704037666320803, -0.7748647689819338, -0.25859284400939964, 0.17421040534973123, 0.6567186832427976, 2.645513582229614]
Final Reward:  89.74106584930179
Mean Error:  0.002155133817777292
Max Error:  0.013265179703838975
Best Model Evaluation Results:
Mean Reward: 91.96110872144841, Std Reward: 1.4210854715202004e-14
Final Chosen Points:  [-5.532826685905457, -3.1540277481079104, -2.0710525035858156, -0.7831099987030031, -0.2647798061370852, 0.16862807273864724, 0.64826865196228, 2.658220338821411]
Final Reward:  90.84385950155735
Mean Error:  0.002203441153874171
Max Error:  0.013084013046487805
Running with OneCycleLR_Schedule_Cosine and config {'initial_value': 0.005, 'warmup_proportion': 0.2, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:42:22 < 0:00:00 , 72 it/s ]
Final Model Evaluation Results:
Mean Reward: 3.473199, Std Reward: 0.0
Final Chosen Points:  [0.1, 2.778163266181946, 3.318390536308289, 4.363284611701966, 4.463284611701965, 4.563284611701965, 5.946730685234069, 6.046730685234069]
Final Reward:  8.439789937926378
Mean Error:  0.01877490960026011
Max Error:  0.14328922424252288
Best Model Evaluation Results:
Mean Reward: 88.09266689668243, Std Reward: 0.0
Final Chosen Points:  [-5.177278780937195, -2.3768299102783206, -1.2797798633575441, -0.7322472095489504, -0.24906635284423848, 0.1960655212402342, 0.6756717681884764, 2.5238881587982176]
Final Reward:  86.97317008546257
Mean Error:  0.0024223124641663267
Max Error:  0.013641670231025804
Running with OneCycleLR_Schedule_Exponential and config {'initial_value': 0.0005, 'warmup_proportion': 0.1, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:42:42 < 0:00:00 , 74 it/s ]
Final Model Evaluation Results:
Mean Reward: 50.105132000000005, Std Reward: 7.105427357601002e-15
Final Chosen Points:  [-5.200285816192627, -2.469433116912842, -0.9942430973052981, -0.4596291542053226, 0.0595712661743161, 0.6955247879028317, 1.5745460510253904, 3.225337553024292]
Final Reward:  49.00036556162054
Mean Error:  0.0038117118416476493
Max Error:  0.024432085805262127
Best Model Evaluation Results:
Mean Reward: 53.712952445706875, Std Reward: 0.0
Final Chosen Points:  [-5.559936666488648, -2.4935453414916995, -1.162751626968384, -0.5385921955108645, 0.08394360542297344, 0.6603332519531248, 1.5790304660797116, 3.1097858428955076]
Final Reward:  52.61777975137565
Mean Error:  0.003758650823290038
Max Error:  0.02269156581439208
Running with OneCycleLR_Schedule_Exponential and config {'initial_value': 0.001, 'warmup_proportion': 0.1, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:44:15 < 0:00:00 , 72 it/s ]
Final Model Evaluation Results:
Mean Reward: 98.199651, Std Reward: 0.0
Final Chosen Points:  [-5.436054730415345, -2.552006769180298, -0.7686621665954593, -0.36639604568481476, 0.022125959396362, 0.40784940719604457, 0.8509339809417721, 2.5408034801483153]
Final Reward:  97.06485089034011
Mean Error:  0.002197018648109393
Max Error:  0.01220373349263637
Best Model Evaluation Results:
Mean Reward: 99.0935396819405, Std Reward: 1.4210854715202004e-14
Final Chosen Points:  [-5.454053068161011, -2.569319772720337, -0.7750508308410647, -0.38339099884033234, 0.0032856464385983275, 0.3990651130676266, 0.8412115097045895, 2.54964165687561]
Final Reward:  97.95824200847979
Mean Error:  0.0022161082808690286
Max Error:  0.012081512261346017
Running with OneCycleLR_Schedule_Exponential and config {'initial_value': 0.005, 'warmup_proportion': 0.1, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:45:59 < 0:00:00 , 72 it/s ]
Final Model Evaluation Results:
Mean Reward: 104.43731199999999, Std Reward: 1.4210854715202004e-14
Final Chosen Points:  [-5.666058683395386, -2.542495357990265, -0.7659559369087222, -0.4060470223426822, -0.04417401552200348, 0.3210988402366635, 0.706347835063934, 2.575540769100189]
Final Reward:  103.29428587318377
Mean Error:  0.0021719477645637825
Max Error:  0.011433360093046864
Best Model Evaluation Results:
Mean Reward: 104.90881930725917, Std Reward: 1.4210854715202004e-14
Final Chosen Points:  [-5.661016845703125, -2.508599627017975, -0.7374415516853335, -0.4051610589027408, -0.06370645761489899, 0.30047706365585297, 0.7009133219718929, 2.5832607626914976]
Final Reward:  103.76267520670903
Mean Error:  0.0021846709598450685
Max Error:  0.011375553275180583
Running with OneCycleLR_Schedule_Exponential and config {'initial_value': 0.0005, 'warmup_proportion': 0.2, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:44:42 < 0:00:00 , 70 it/s ]
Final Model Evaluation Results:
Mean Reward: 46.589996, Std Reward: 0.0
Final Chosen Points:  [-3.174879813194275, -1.2883021116256712, -0.8730610132217406, -0.3635356187820433, 0.07619893550872817, 0.5945482015609742, 1.3495364904403688, 2.9590284109115603]
Final Reward:  45.475461692809276
Mean Error:  0.005261233409811291
Max Error:  0.026047043143698212
Best Model Evaluation Results:
Mean Reward: 57.697045450506266, Std Reward: 0.0
Final Chosen Points:  [-3.8838619008660316, -1.8390422120690344, -0.9766058221459387, -0.42073781639337526, 0.13084246963262572, 0.6516913160681725, 1.391927455365658, 3.075456450879574]
Final Reward:  56.59138921095719
Mean Error:  0.004991723191092899
Max Error:  0.020715235218797645
Running with OneCycleLR_Schedule_Exponential and config {'initial_value': 0.001, 'warmup_proportion': 0.2, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:42:49 < 0:00:00 , 74 it/s ]
Final Model Evaluation Results:
Mean Reward: 100.815394, Std Reward: 0.0
Final Chosen Points:  [-5.233311319351197, -2.56183032989502, -0.7882167816162112, -0.3946271896362308, -0.030145645141601868, 0.3361273765563962, 0.7395193099975582, 2.5397103309631346]
Final Reward:  99.67513138018951
Mean Error:  0.0021640673971004285
Max Error:  0.011874724082704624
Best Model Evaluation Results:
Mean Reward: 102.77451601205007, Std Reward: 0.0
Final Chosen Points:  [-5.234115266799927, -2.574202942848206, -0.7921059846878055, -0.40088388919830353, -0.041050791740417786, 0.3235327959060666, 0.7238863229751583, 2.5563711404800413]
Final Reward:  101.6334568737684
Mean Error:  0.0021930133839368426
Max Error:  0.01162584616759954
Running with OneCycleLR_Schedule_Exponential and config {'initial_value': 0.005, 'warmup_proportion': 0.2, 'multiplier': 20}
Run #1
 100% ------------------------ 200,704/200,000  [ 0:44:37 < 0:00:00 , 70 it/s ]
Final Model Evaluation Results:
Mean Reward: 104.645609, Std Reward: 0.0
Final Chosen Points:  [-5.235931062698365, -2.5007766962051394, -0.7555788278579715, -0.35453197956085236, -0.0019177198410037233, 0.38385555744171107, 0.715246748924255, 2.5677239179611204]
Final Reward:  103.50501864613315
Mean Error:  0.002154171215187971
Max Error:  0.011413166290604959
Best Model Evaluation Results:
Mean Reward: 104.88801616722819, Std Reward: 1.4210854715202004e-14
Final Chosen Points:  [-5.221482300758362, -2.4876482963562014, -0.7335819721221927, -0.3379765510559085, 0.02338337898254364, 0.39054260253906214, 0.7429093837738033, 2.5852816581726072]
Final Reward:  103.74795491358401
Mean Error:  0.002144900362467192
Max Error:  0.011387205175224846

Process finished with exit code 0
